{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e3273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf4863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aaea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_old_round = True\n",
    "target_column_name = 'target'\n",
    "round_number = 1112\n",
    "data_folder = 'data_folder'\n",
    "data_version = 'v5.0'\n",
    "live_example_preds_filename = 'live_example_preds.parquet'\n",
    "live_example_round_filename = 'live_example_round.parquet'\n",
    "train_file_name = 'train.parquet'\n",
    "validation_example_filename = 'validation_example_round.parquet'\n",
    "validation_filename = 'validation.parquet'\n",
    "target_column_name = 'target'\n",
    "feature_set_chosen =  'small'\n",
    "\n",
    "feature_metadata = json.load(open(f\"{data_folder}/{data_version}/{round_number}/features.json\"))\n",
    "for metadata in feature_metadata:\n",
    "  print(metadata, len(feature_metadata[metadata]))\n",
    "\n",
    "group_split_list = ['week_no', 'year_horizon']\n",
    "feature_set = feature_metadata[\"feature_sets\"][feature_set_chosen]\n",
    "target_set = feature_metadata['targets']\n",
    "relevant_columns_list = feature_set + [target_column_name] + group_split_list\n",
    "\n",
    "all_features_list = feature_set + group_split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01d82a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaf104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if download_old_round:\n",
    "    raw_df = pd.read_parquet(\n",
    "        f\"{data_folder}/{data_version}/{round_number}/train.parquet\",\n",
    "        columns=['era'] + feature_set + target_set\n",
    "    )\n",
    "\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abd1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d5f2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_df = raw_df.copy(deep=True)\n",
    "\n",
    "sliced_df['week_no'] = (sliced_df['era'].astype(int) - 1) % 52 + 1\n",
    "sliced_df['year_horizon'] = (sliced_df['era'].astype(int) - 1) // 52 + 1\n",
    "sliced_df['era'] = sliced_df['era'].astype(int)\n",
    "\n",
    "train_df = sliced_df[relevant_columns_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab95dc0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97fcfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute feature correlations with the target\n",
    "correlations = sliced_df[relevant_columns_list].corr(numeric_only=True)['target'].sort_values(ascending=False)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fedb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6696222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_indices_series = train_df.groupby(group_split_list).ngroup()\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=2, test_size=0.7, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in gss.split(train_df, groups=group_indices_series):\n",
    "    train_split_df = train_df.iloc[train_idx]\n",
    "    test_split_df = train_df.iloc[test_idx]\n",
    "\n",
    "X_train = train_split_df[all_features_list]\n",
    "y_train = train_split_df[target_column_name]\n",
    "\n",
    "X_test = test_split_df[all_features_list]\n",
    "y_test = test_split_df[target_column_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9167ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da4fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "r2_score_value_rf = r2_score(y_test, y_pred_rf)\n",
    "rmse_value_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "mae_value_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse_value_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest R2 Score: {r2_score_value_rf:.4f}\")\n",
    "print(f\"Random Forest RMSE: {rmse_value_rf:.2f}\")\n",
    "print(f\"Random Forest MAE: {mae_value_rf:.2f}\")\n",
    "print(f\"Random Forest MSE: {mse_value_rf:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
